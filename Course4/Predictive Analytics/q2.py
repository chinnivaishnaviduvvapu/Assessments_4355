# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TCYjQ_soR2LrxSO3XSabKJK2VgmUA64-
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')
import time
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,r2_score,mean_squared_error,precision_score, recall_score, f1_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from matplotlib import pyplot as plt
from sklearn.metrics import silhouette_score
from numpy import loadtxt
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression,LinearRegression
from sklearn.svm import SVC
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
import seaborn as sn
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import silhouette_score
import seaborn as sns
from sklearn.ensemble import IsolationForest
from statsmodels.stats.outliers_influence import variance_inflation_factor

df=pd.read_csv("/content/sample_data/penguins_classification.csv")
df.head()

df.shape

df.info()

df.dtypes

df.isna().sum()

from sklearn.impute import KNNImputer
impute=KNNImputer()
for i in df.select_dtypes(include="number").columns:
  df[i]=impute.fit_transform(df[[i]])

df.species.value_counts()

df.island.value_counts()

df['species']=LabelEncoder().fit_transform(df['species'])

df.head()

df=pd.get_dummies(df,columns=["island"],dtype="int")

df.head()

for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

df.describe()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

#outliers detection
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

# handling the outliers using iqr
for columns in df.select_dtypes(include="number"):
  q1=df[columns].quantile(0.25)
  q3=df[columns].quantile(0.75)
  iqr=q3-q1
  lower=q1-1.5*iqr
  upper=q3+1.5*iqr
  new_df=df.loc[(df[columns]<upper)&(df[columns]>lower)]

# Feature selection and data cleaning
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
# Compute the correlation matrix for numerical variables
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)
plt.figure(figsize=(8, 5))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

df.columns

x=df.drop(columns=['species'],axis=1)
y=df['species']

x.head()

y.head()

scaler = StandardScaler()
for column in x.select_dtypes(include=['float64','int64']):
  x[column] = scaler.fit_transform(x[[column]])

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)

model=LogisticRegression()
model.fit(x_train,y_train)

y_pred=model.predict(x_test)
y_pred

print("Coefficients:", model.coef_)
print("Intercept:", model.intercept_)

ac=accuracy_score(y_test, y_pred)
ac

f1=f1_score(y_test, y_pred)
f1

r=recall_score(y_test, y_pred)
r

p=precision_score(y_test, y_pred)
p

c=classification_report(y_test, y_pred)
c

cm=confusion_matrix(y_test, y_pred)
cm

sns.heatmap(cm,annot=True)